{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Create matches by team DataFrame\n",
    "\n",
    "When analyzing the data, we also like to have a dataframe `df_mbt (df_matches_by_team)` that contains, for each match, a separate row for each team participating in that match.\n",
    "This structure is nicely visualized [at the Nufflytics blog](https://www.nufflytics.com/post/the-value-of-tv/).\n",
    "Such a dataset is suitable for adding, at the match level, data that is specific for each team - coach pair, such as team value, coach rating etc.\n",
    "For example, we can imagine adding more team level data, such as casualties caused during the match, or team composition at the start of the match etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotnine as p9\n",
    "import h5py\n",
    "\n",
    "from mizani.formatters import date_format\n",
    "\n",
    "# point this to the location of the  datasets\n",
    "path_to_datasets = 'datasets/current/'\n",
    "\n",
    "# FUMBBL matches\n",
    "target = 'df_matches.csv'\n",
    "df_matches = pd.read_csv(path_to_datasets + target) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO fix coach name changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matches[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make two copies, one for each team in the match\n",
    "team1_data = df_matches[['match_id', 'match_date', 'week_number',\t'year',\t'week_year', 'week_date',\n",
    "                          'team1_id', 'division_id', 'division_name', 'scheduler' , 'group_id', 'group_name',  'tournament_id' , 'tournament_name',\n",
    "    'team1_coach_id', 'coach1_ranking', 'team1_race_name', 'team1_value', 'team1_score', 'team1_win', 'tv_diff', 'tv_match', 'team2_coach_id', 'team2_race_name', 'team2_value', 'team2_score', \n",
    "    'team1_comp', 'team1_pass', 'team1_rush', 'team1_block', 'team1_foul', 'team1_cas', 'team1_cas_bh', 'team1_cas_si', 'team1_cas_rip',\n",
    "    'team2_comp', 'team2_pass', 'team2_rush', 'team2_block', 'team2_foul', 'team2_cas', 'team2_cas_bh', 'team2_cas_si', 'team2_cas_rip',\n",
    "    'tv_bin', 'tv_bin2', 'mirror_match', 'coach1_CR', 'coach2_CR', 'coach1_CR_bin', 'CR_diff',  'has_sp']].copy()\n",
    "\n",
    "team2_data = df_matches[['match_id', 'match_date', 'week_number',\t'year',\t'week_year', 'week_date', \n",
    "                         'team2_id',  'division_id', 'division_name', 'scheduler' , 'group_id', 'group_name',  'tournament_id' , 'tournament_name',\n",
    "    'team2_coach_id', 'coach2_ranking', 'team2_race_name', 'team2_value', 'team2_score', 'team2_win', 'tv_diff', 'tv_match', 'team1_coach_id', 'team1_race_name', 'team1_value', 'team1_score',\n",
    "    'team2_comp', 'team2_pass', 'team2_rush', 'team2_block', 'team2_foul', 'team2_cas', 'team2_cas_bh', 'team2_cas_si', 'team2_cas_rip',\n",
    "    'team1_comp', 'team1_pass', 'team1_rush', 'team1_block', 'team1_foul', 'team1_cas', 'team1_cas_bh', 'team1_cas_si', 'team1_cas_rip',\n",
    "    'tv_bin', 'tv_bin2', 'mirror_match', 'coach2_CR', 'coach1_CR', 'coach2_CR_bin','CR_diff', 'has_sp']].copy()\n",
    "\n",
    "\n",
    "team1_data.columns = team2_data.columns = ['match_id', 'match_date', 'week_number',\t'year',\t'week_year', 'week_date', \n",
    "                                           'team_id', 'division_id', 'division_name', 'scheduler' , 'group_id', 'group_name',  'tournament_id' , 'tournament_name',\n",
    "    'coach_id', 'coach_name', 'race_name', 'team_value', 'team_score', 'wins', 'tv_diff', 'tv_match',  'away_coach_id', 'away_race_name', 'away_team_value', 'away_team_score',\n",
    "    'home_comp', 'home_pass', 'home_rush', 'home_block', 'home_foul',  'home_cas', 'home_cas_bh', 'home_cas_si', 'home_cas_rip',\n",
    "    'away_comp', 'away_pass', 'away_rush', 'away_block', 'away_foul',  'away_cas', 'away_cas_bh', 'away_cas_si', 'away_cas_rip',\n",
    "    'tv_bin', 'tv_bin2', 'mirror_match', 'coach_CR', 'away_coach_CR', 'coach_CR_bin','CR_diff', 'has_sp']\n",
    "\n",
    "team1_data[ 'team'] = 'team1'\n",
    "team2_data[ 'team'] = 'team2'\n",
    "# combine both dataframes\n",
    "df_mbt = pd.concat([team1_data, team2_data])\n",
    "\n",
    "df_mbt['tv_diff2'] = df_mbt['team_value'] - df_mbt['away_team_value']\n",
    "df_mbt['cr_diff2'] = df_mbt['coach_CR'] - df_mbt['away_coach_CR']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding outcome weights\n",
    "\n",
    "One way to measure team strength is to calculate a win rate.\n",
    "If we want to calculate win rates, we need to decide how to weigh a draw.\n",
    "In Blood Bowl data analysis, it seems that a 2:1:0 (W / D / L) weighting scheme is most commonly used. \n",
    "So if we want to compare with others, it makes sense to adapt this scheme as well.\n",
    "If we divide these weights by two we get something that, if we average it, we can interpret as a win rate.\n",
    "\n",
    "This scheme has the advantage that the weighted average win percentage over all matches is always 50%, creating a nice reference point allowing conclusions such as \"this and that team has an x percent above average win percentage\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mbt.loc[df_mbt['wins'] == 0, 'wins'] = 0.5\n",
    "df_mbt.loc[df_mbt['wins'] == -1, 'wins'] = 0\n",
    "\n",
    "# convert to float\n",
    "df_mbt['wins'] = df_mbt['wins'].astype(float)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, Lets have a look at our dataset again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mbt.query(\"coach_id == 255851\").sort_values('match_date')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: adding race classifications to df_mbt (team tiers, bash/dash/hybrid)\n",
    "\n",
    "There are team classifications for strength (tiers) and classifications that focus on play style (Bash/Dash/Hybrid).\n",
    "The Bash/Dash/Hybrid classification i use is based on this great [Nufflytics blog](https://www.nufflytics.com/post/bash-dash-hybrid-by-the-numbers/), and my own subjective choices.\n",
    "Here we add both to the `df_mbt` dataframe, as in this dataset each row is about a single team, instead of a pairing.\n",
    "\n",
    "According to [this article from the NAF from 2017](https://www.thenaf.net/2017/05/tiers/), already since 2010 efforts were made to balance things out a bit between the different team strengths. For example, the weaker teams get more gold to spend on players, or get more so-called \"Star player points\" to spend on skilling players up. \n",
    "\n",
    "According to [the NAF](https://www.thenaf.net/tournaments/information/tiers-and-tiering/), traditionally team tiering consists of three groups, with Tier 1 being the strongest teams, and tier 3 the weakest teams. \n",
    "\n",
    "The GW BB2020 rule book also contains three tier groups, that are similar to the NAF tiers: except for Humans and Old World Alliance. \n",
    "\n",
    "And in november 2021, Games Workshop published an update of the three tier groups, now with High Elves moving from tier 2 to tier 1, and Old World Alliance moving back to tier 2.\n",
    "\n",
    "Finally, I added an additional race classification into the well known bash/dash (agile)/hybrid / stunty classes.\n",
    "\n",
    "**PM Vampires is on other**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_tiers = pd.read_csv('codelists/race_tiers_mapping.csv')\n",
    "#race_tiers = race_tiers[ ['race_name', 'bb2020_tier', 'naf_tier', 'bb2020_nov21_tier', 'race_type']]\n",
    "#race_tiers = race_tiers.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_tiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add bb2020 tiers\n",
    "df_mbt = pd.merge(df_mbt, race_tiers, on='race_name', how='left')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'datasets/current/df_mbt'\n",
    "\n",
    "#df_mbt.to_hdf(target + '.h5', key='df_mbt', mode='w', format = 't',  complevel = 9)\n",
    "df_mbt.to_csv(target + '.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "requests_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
